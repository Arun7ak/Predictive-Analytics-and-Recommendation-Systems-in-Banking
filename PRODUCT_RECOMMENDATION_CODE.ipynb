{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTED LIBRARIES FOR HANDLING AND GENERATING THE FAKE RANDOM DATAFRAME\n",
    "import pandas as pd\n",
    "import random\n",
    "from faker import Faker\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATED THE FAKE DATA USING FAKER LIBRARIES\n",
    "fake = Faker()\n",
    "num_records = 1000  \n",
    "\n",
    "customers = [f'CUST{str(i).zfill(4)}' for i in range(1, 101)]  \n",
    "products = [f'PROD{str(i).zfill(4)}' for i in range(1, 51)]  \n",
    "interaction_types = ['purchased', 'viewed', 'clicked','Added to Cart']\n",
    "\n",
    "data = []\n",
    "for _ in range(num_records):\n",
    "    customer_id = random.choice(customers)\n",
    "    product_id = random.choice(products)\n",
    "    interaction_type = random.choice(interaction_types)\n",
    "    interaction_date = fake.date_between(start_date='-1y', end_date='today')  \n",
    "    \n",
    "    data.append({\n",
    "        'customer_id': customer_id,\n",
    "        'product_id': product_id,\n",
    "        'interaction_type': interaction_type,\n",
    "        'interaction_date': interaction_date\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAY THE DATAFRAME\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAPPING THE SCORE TO THE DATAFRAME BASED ON INTERACTION TYPE\n",
    "interaction_mapping = {'purchased': 4,'Added to Cart':3 ,'viewed': 2, 'clicked': 1}\n",
    "df['interaction_score'] = df['interaction_type'].map(interaction_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id          0\n",
       "product_id           0\n",
       "interaction_type     0\n",
       "interaction_date     0\n",
       "interaction_score    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CHECKING THE NULL VALUES\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CHECKING THE DUPLICATED VALUE\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAY THE DATAFRAME AFTER MAPPING \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTED LIBARIES FOR EDA AND CHECK OUTLIER\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE OUTLIER\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.boxplot(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING THE PIVOT TABLE FOR TRAINING\n",
    "interaction_matrix = df.pivot_table(index='customer_id', columns='product_id', values='interaction_score', aggfunc='sum', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAY THE PIVOT TABLE\n",
    "interaction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REPLACE THE VALUE 0 WITH 0.01\n",
    "interaction_matrix = interaction_matrix.replace(0, 0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT CSR MATRIX TO HANDLE THE SPARSE DATA\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HANDLING THE SPARSE DATA\n",
    "interaction_matrix_sparse = csr_matrix(interaction_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING THE MODEL USING SVD \n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "svd_matrix = svd.fit_transform(interaction_matrix_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USED COSINE WHICH IS COLLABERATIVE FILTERING\n",
    "svd_similarity = cosine_similarity(svd_matrix)\n",
    "svd_similarity_df = pd.DataFrame(svd_similarity, index=interaction_matrix.index, columns=interaction_matrix.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAY THE DATAFRAME \n",
    "svd_similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO RECOMMEND PRODUCTS USING SVD-BASED SIMILARITY FOR A GIVEN USER\n",
    "def recommend_products_svd(user_id, num_recommendations=5):\n",
    "    if user_id not in interaction_matrix.index:\n",
    "        return f\"User {user_id} not found in dataset.\"\n",
    "\n",
    "    similar_users = svd_similarity_df[user_id].sort_values(ascending=False).iloc[1:].index\n",
    "\n",
    "    similar_users_interactions = interaction_matrix.loc[similar_users]\n",
    "\n",
    "    product_scores = similar_users_interactions.sum().sort_values(ascending=False)\n",
    "\n",
    "    user_interactions = set(interaction_matrix.loc[user_id][interaction_matrix.loc[user_id] > 0].index)\n",
    "\n",
    "    recommendations = [prod for prod in product_scores.index if prod not in user_interactions][:num_recommendations]\n",
    "\n",
    "    return recommendations if recommendations else \"No new recommendations available.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTED JOBLIB AND SAVED THE MODEL USING JOBLIB\n",
    "import joblib\n",
    "\n",
    "joblib.dump(svd,r'd:\\BANK PROJECT\\svd.pkl')\n",
    "\n",
    "joblib.dump(interaction_matrix, r'd:\\BANK PROJECT\\interaction mat.pkl')\n",
    "\n",
    "joblib.dump(svd_similarity_df, r'd:\\BANK PROJECT\\svd sim.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECOMMEND PRODUCTS FOR A GIVEN USER BASED ON SVD SIMILARITY \n",
    "user_id = \"CUST0001\"\n",
    "recommended_products_svd = recommend_products_svd(user_id)\n",
    "print(f\"Recommended products for User {user_id} with SVD: {recommended_products_svd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE PRECISION AND RECALL FOR THE TRAINED MODEL\n",
    "def precision_at_k(actual, predicted, k=5):\n",
    "    return sum(1 for x in predicted[:k] if x in actual) / k\n",
    "\n",
    "def recall_at_k(actual, predicted, k=5):\n",
    "    return sum(1 for x in predicted[:k] if x in actual) / len(actual) if actual else 0\n",
    "\n",
    "actual = ['PROD001', 'PROD002', 'PROD003']\n",
    "predicted = ['PROD002', 'PROD003', 'PROD004'] \n",
    "\n",
    "print(\"Precision@K:\", precision_at_k(actual, predicted, k=3))\n",
    "print(\"Recall@K:\", recall_at_k(actual, predicted, k=3))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
