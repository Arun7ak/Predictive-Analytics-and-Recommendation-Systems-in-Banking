{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                    CUSTOMER SEGMENTATION USING MACHINE LEARNING(UNSUPERVISED LEARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING LIBRARIES FOR HANDLING AND GENERATING FAKE DATAFRAME\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERTING FAKE DATA\n",
    "fake = Faker()\n",
    "\n",
    "num_customers = 2500\n",
    "max_transactions_per_customer = 20 \n",
    "\n",
    "customers = [f\"CUST{str(i).zfill(6)}\" for i in range(1, num_customers + 1)]\n",
    "\n",
    "transaction_data = []\n",
    "for customer_id in customers:\n",
    "    num_transactions = random.randint(1, max_transactions_per_customer)\n",
    "    for _ in range(num_transactions):\n",
    "        transaction_data.append({\n",
    "            \"customer_id\": customer_id,\n",
    "            \"transaction_id\": f\"TRANS{str(len(transaction_data) + 1).zfill(6)}\",\n",
    "            \"transaction_amount\": np.random.uniform(10, 1000),\n",
    "            \"transaction_type\": random.choice([\"deposit\", \"withdrawal\"]),\n",
    "            \"transaction_date\": fake.date_between(start_date='-1y', end_date='today'),\n",
    "        })\n",
    "\n",
    "transaction_data = pd.DataFrame(transaction_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAY THE DATAFRAME\n",
    "transaction_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE THE FAKE DATASET IN CSV FILE\n",
    "transaction_data.to_csv(\"Loan Transaction data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ THE FAKE DATA \n",
    "transaction_data = pd.read_csv(r\"D:\\BANK PROJECT\\Loan Transaction data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAY THE DATAFRAME\n",
    "transaction_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                  DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE TOTAL TRANSACTION AND COUNT THE TOTAL CUSTOMER \n",
    "print(f\"Total transactions: {len(transaction_data)}\")\n",
    "print(f\"Unique customers: {transaction_data['customer_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE NULL VALES \n",
    "transaction_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING DUPLICATE VALUE\n",
    "transaction_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK THE INFO OF DATAFRAME\n",
    "transaction_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE THE DATAFRAME \n",
    "transaction_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE ALL COLUMNS COUNTS\n",
    "transaction_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK THE DATATYPE OF THE DATAFRAME\n",
    "transaction_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK THE VALUE COUNT IN TRANSACTIO TYPE COLUMN\n",
    "transaction_data['transaction_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING LIBRARIES FOR EDA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE OUTLIER\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.boxplot(data=transaction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONVERTING THE COLUMN TO CORRECT DATATYPE\n",
    "transaction_data['transaction_date'] = pd.to_datetime(transaction_data['transaction_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONVERTING THE RUPEES TO DOLLAR\n",
    "transaction_data[\"transaction_amount\"] = transaction_data[\"transaction_amount\"] / 86.66\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROUNDING THE COLUMNS VALUES\n",
    "transaction_data['transaction_amount'] = transaction_data['transaction_amount'].round(1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAY THE DATAFRAME\n",
    "transaction_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING NEW COLUMNS\n",
    "elements = ['withdrawal','deposit']\n",
    "\n",
    "for element in elements:\n",
    "    Tranformed_Columns = transaction_data['transaction_type'] == element\n",
    "    transaction_data[f'{element}_Value'] = transaction_data['transaction_amount'].where(Tranformed_Columns,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILLING THE NULL WITH 0 FOR SUM IT\n",
    "transaction_data.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GROUPING THE COLUMNS FOR TRAINING THE MODEL MORE EFFICIENTLY\n",
    "customer_data = transaction_data.groupby(\"customer_id\").agg(\n",
    "    total_no_of_transactions=(\"transaction_id\", \"count\"),\n",
    "    total_amount_in_dollar=(\"transaction_amount\", \"sum\"),\n",
    "    num_of_deposits=(\"transaction_type\", lambda x: (x == \"deposit\").sum()),\n",
    "    num_of_withdrawals=(\"transaction_type\", lambda x: (x == \"withdrawal\").sum()),\n",
    "    withdrawals_amount_in_dollar=(\"withdrawal_Value\",'sum'),\n",
    "    deposits_amount_in_dollar=(\"deposit_Value\",'sum')\n",
    ").reset_index()\n",
    "customer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data[\"balance_amount_in_dollar\"] = customer_data[\"deposits_amount_in_dollar\"] - customer_data[\"withdrawals_amount_in_dollar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data.rename(columns={\"total_amount_in_dollar\": \"total_transaction_amount_in_dollar\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AGAIN CHECK THE DATATYPE AFTER GROUPING\n",
    "customer_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE NULL VALUE AFTER GROUPING\n",
    "customer_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                             EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT TOP 10 CUSTOMERS BASED ON TOTAL AMOUNT IN DESCENDING ORDER\n",
    "top_10 = customer_data[[\"customer_id\",\"total_no_of_transactions\",\"total_transaction_amount_in_dollar\"]].sort_values(by='total_transaction_amount_in_dollar', ascending=False).head(10)\n",
    "plt.figure(figsize=(13, 5))\n",
    "sns.barplot(y=\"customer_id\", x=\"total_transaction_amount_in_dollar\", data=top_10, orient='h')\n",
    "plt.xlabel(\"total_transaction_amount_in_dollar\")\n",
    "plt.ylabel(\"Customer ID\")\n",
    "plt.title(\"Top 10 Customers by Total Amount\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELECT TOP 10 CUSTOMERS BASED ON WITHDRAWALS AMOUNT \n",
    "top_10 = customer_data[[\"customer_id\",\"withdrawals_amount_in_dollar\"]].sort_values(by='withdrawals_amount_in_dollar', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(13, 5))\n",
    "sns.barplot(x=\"customer_id\", y=\"withdrawals_amount_in_dollar\", data=top_10, palette=\"coolwarm\")\n",
    "plt.title(\"Top 10 Customers by Withdrawals Amount\", fontsize=16, fontweight=\"bold\")\n",
    "plt.xlabel(\"Customer ID\", fontsize=14)\n",
    "plt.ylabel(\"Withdrawals Amount\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A DISTRIBUTION PLOT FOR TOTAL AMOUNT WITH KDE\n",
    "sns.displot(data=customer_data, x=\"total_transaction_amount_in_dollar\", kde=True)  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT TOP 10 CUSTOMERS BASED ON DEPOSITS AMOUNT \n",
    "top_10 = customer_data[[\"customer_id\",\"deposits_amount_in_dollar\"]].sort_values(by='deposits_amount_in_dollar', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(13, 5))\n",
    "sns.barplot(x=\"customer_id\", y=\"deposits_amount_in_dollar\", data=top_10, palette=\"Greens\")\n",
    "plt.title(\"Top 10 Customers by Deposits Amount\", fontsize=16, fontweight=\"bold\")\n",
    "plt.xlabel(\"Customer ID\", fontsize=14)\n",
    "plt.ylabel(\"Deposits Amount\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE CORRELATION FOR NUMERIC COLUMNS USING HEATMAP\n",
    "correlation_matrix = customer_data[[\"total_no_of_transactions\",\n",
    "                                    \"num_of_deposits\", \"num_of_withdrawals\", \"withdrawals_amount_in_dollar\", \"deposits_amount_in_dollar\",\"total_transaction_amount_in_dollar\",\"balance_amount_in_dollar\"]].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING OUTLIER FOR ALL THE COLUMNS\n",
    "plt.figure(figsize=(16, 5))\n",
    "sns.boxplot(data = customer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = customer_data['deposits_amount_in_dollar'].quantile(0.25)\n",
    "Q3 = customer_data['deposits_amount_in_dollar'].quantile(0.75)\n",
    "\n",
    "# Calculate the Interquartile Range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Determine the upper and lower bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify outliers\n",
    "outliers = customer_data[(customer_data['deposits_amount_in_dollar'] < lower_bound) | (customer_data['deposits_amount_in_dollar'] > upper_bound)]\n",
    "\n",
    "# Display results\n",
    "print(\"Lower bound:\", lower_bound)\n",
    "print(\"Upper bound:\", upper_bound)\n",
    "outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = customer_data['withdrawals_amount_in_dollar'].quantile(0.25)\n",
    "Q3 = customer_data['withdrawals_amount_in_dollar'].quantile(0.75)\n",
    "\n",
    "# Calculate the Interquartile Range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Determine the upper and lower bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify outliers\n",
    "outliers = customer_data[(customer_data['withdrawals_amount_in_dollar'] < lower_bound) | (customer_data['withdrawals_amount_in_dollar'] > upper_bound)]\n",
    "\n",
    "# Display results\n",
    "print(\"Lower bound:\", lower_bound)\n",
    "print(\"Upper bound:\", upper_bound)\n",
    "outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "customer_data = customer_data[\n",
    "    (customer_data['withdrawals_amount_in_dollar'] >= lower_bound) & \n",
    "    (customer_data['withdrawals_amount_in_dollar'] <= upper_bound)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "customer_data = customer_data[\n",
    "    (customer_data['deposits_amount_in_dollar'] >= lower_bound) & \n",
    "    (customer_data['deposits_amount_in_dollar'] <= upper_bound)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE THE DATASET AFTER CLEANING\n",
    "customer_data.to_csv(\"cleaned_loan_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ THE CLEANED DATASET\n",
    "customer_data = pd.read_csv(\"d:/BANK PROJECT/cleaned_loan_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAY THE DATAFRAME \n",
    "customer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK THE DATATYPE AFTER ALL CLEANING DONE\n",
    "customer_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                   DATA PREPROCESSING AND MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTED ALL THE LIBRARIES FOR TRAINING,EVALUATE THE MODLE AND EVALUATE THE MODEL\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from imblearn.over_sampling import KMeansSMOTE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENCODE THE TRAINING DATA COLUMNS\n",
    "features = customer_data[[\"total_no_of_transactions\", \"total_transaction_amount_in_dollar\", \"num_of_deposits\", \n",
    "                          \"num_of_withdrawals\", \"withdrawals_amount_in_dollar\", \"deposits_amount_in_dollar\"]]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "scaled_customer_data = pd.DataFrame(scaled_features, columns=features.columns.tolist())\n",
    "scaled_customer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN THE DATA USING KMEANS CLUSTERING\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10, max_iter=300, algorithm='lloyd')\n",
    "\n",
    "customer_data['cluster'] = kmeans.fit_predict(scaled_customer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPERTUNING THE CENTROID BASED K MEANS CLUSTERING MODEL \n",
    "kmeans = KMeans(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_clusters': np.arange(2, 11), \n",
    "    'init': ['k-means++', 'random'],  \n",
    "    'max_iter': [300, 500, 1000],  \n",
    "    'n_init': [10, 15],  \n",
    "    'tol': [1e-4, 1e-3],  \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(kmeans, param_grid, cv=3, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(scaled_customer_data)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "best_kmeans = KMeans(**grid_search.best_params_, random_state=42)\n",
    "customer_data[\"cluster\"] = best_kmeans.fit_predict(scaled_customer_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USING THE ELBOW METHOD CHECKED THE BEST NUMBER OF CLUSTER\n",
    "inertia = []\n",
    "for k in range(2, 11):  \n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(scaled_customer_data)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(2, 11), inertia, marker='o')\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISPLAY THE DATAFRAME AFTER CLUSTERING\n",
    "customer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKED THE SCORE FOR KMEANS CLUSTERING MODEL\n",
    "silhouette = silhouette_score(scaled_customer_data, customer_data[\"cluster\"])\n",
    "db_index = davies_bouldin_score(scaled_customer_data, customer_data[\"cluster\"])\n",
    "\n",
    "print(f\"Silhouette Score: {round(silhouette, 2)}\")\n",
    "print(f\"Davies-Bouldin Index: {db_index}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAY THE PCA PLOT KMEANS MODEL\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(scaled_features)\n",
    "\n",
    "plt.scatter(data_pca[:, 0], data_pca[:, 1], c=customer_data[\"cluster\"], cmap='viridis', s=50)\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', marker='X', s=200)\n",
    "plt.title('Cluster Visualization (PCA)')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING JOBLIB TO SAVE THE MODEL\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVED THE GOOD SCORE MODEL\n",
    "joblib.dump(kmeans, r\"d:\\BANK PROJECT\\kmeans.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE THE SCALED DATA \n",
    "joblib.dump(scaled_features, r\"d:\\BANK PROJECT\\scaled_d.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING THE DENSITY BASED DBSCAN MODEL\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)  \n",
    "customer_data[\"cluster\"] = dbscan.fit_predict(scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK THE SCORE FOR DBSCAN MODEL\n",
    "if len(set(customer_data[\"cluster\"])) > 1:\n",
    "    silhouette = silhouette_score(scaled_features, customer_data[\"cluster\"])\n",
    "    db_index = davies_bouldin_score(scaled_features, customer_data[\"cluster\"])\n",
    "    print(f\"Silhouette Score: {silhouette}\")\n",
    "    print(f\"Davies-Bouldin Index: {db_index}\")\n",
    "else:\n",
    "    print(\"DBSCAN found less than two clusters; Silhouette Score is not defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAY THE PCA PLOT FOR DBSCAN MODEL\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(scaled_features)\n",
    "\n",
    "plt.scatter(data_pca[:, 0], data_pca[:, 1], c=customer_data[\"cluster\"], cmap='viridis', s=50)\n",
    "plt.title('Cluster Visualization (DBSCAN, PCA)')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINED THE AGGLOMERATIVE CLUSTERING\n",
    "\n",
    "hc = AgglomerativeClustering(n_clusters=2)\n",
    "scaled_customer_data['cluster'] = hc.fit_predict(scaled_customer_data)\n",
    "\n",
    "sch.dendrogram(sch.linkage(scaled_customer_data, method='ward'))\n",
    "\n",
    "scaled_customer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK THE SCORE FOR AGGLOMERATIVE CLUSTERING\n",
    "silhouette = silhouette_score(scaled_customer_data, scaled_customer_data[\"cluster\"])\n",
    "db_index = davies_bouldin_score(scaled_customer_data, scaled_customer_data[\"cluster\"])\n",
    "\n",
    "print(f\"Silhouette Score: {round(silhouette, 2)}\")\n",
    "print(f\"Davies-Bouldin Index: {db_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAY THE PCA PLOT FOR AGGLOMERATIVE CLUSTERING\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(scaled_features)\n",
    "\n",
    "plt.scatter(data_pca[:, 0], data_pca[:, 1], c=scaled_customer_data[\"cluster\"], cmap='viridis', s=50)\n",
    "plt.title('Cluster Visualization (PCA)')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
